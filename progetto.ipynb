{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Progetto di Fornaciari Giacomo<h2>\n",
    "<h3>Matricola: 0001031838<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessari per il progetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzioni fornite per la creazione del dataset di addestramento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_info = tfds.load(\n",
    "    'eurosat/rgb',\n",
    "    shuffle_files=False,\n",
    "    #as_supervised=True,  # Returns a tuple (img, label) instead of a dictionary {'image': img, 'label': label}\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "ds_train = ds_train['train']\n",
    "ds_train = ds_train.shuffle(1000, seed = 42)\n",
    "train_dataset = ds_train.take(20000)\n",
    "test_dataset = ds_train.skip(20000)\n",
    "\n",
    "def generator(dataset,nolines=9):\n",
    "    while True:  # Start an infinite loop\n",
    "        for batch in dataset:\n",
    "            images = batch[\"image\"]\n",
    "            images_np = images.numpy()\n",
    "\n",
    "            masks = np.zeros((batch_size, 64, 64))\n",
    "            for i in range(batch_size):\n",
    "                for j in range(nolines):\n",
    "                    start_point = (np.random.randint(0, 64 - 1), 0)\n",
    "                    end_point = (np.random.randint(0, 64 - 1), 63)\n",
    "                    thickness = np.random.randint(2, 3)\n",
    "                    masks[i] = cv2.line(masks[i], start_point, end_point, (1), thickness)\n",
    "\n",
    "            images_np = images_np / 255.0\n",
    "            masks = np.stack(((masks),) * 3, axis=-1)\n",
    "\n",
    "            yield (images_np * masks, images_np)\n",
    "\n",
    "# Batch the datasets\n",
    "batch_size = 8\n",
    "train_dataset_batched = train_dataset.batch(batch_size)\n",
    "test_dataset_batched = test_dataset.batch(batch_size)\n",
    "\n",
    "# Create generators for the batched datasets\n",
    "train_generator = generator(train_dataset_batched)\n",
    "test_generator = generator(test_dataset_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ho deciso di utilizzare la U-net per il progetto poichè mi dava risultati più soddisfacenti in termini di mean squared error. Questo è il codice usato per la creazione del modello\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model():\n",
    "    input_img = Input(shape=(64, 64, 3))\n",
    "    \n",
    "    # Encoding path\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    # Bottleneck\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
    "    \n",
    "    # Decoding path\n",
    "    u5 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u5 = concatenate([u5, c3])\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(u5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c2])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c1])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    outputs = Conv2D(3, (1, 1), activation='sigmoid')(c7)\n",
    "\n",
    "    model = Model(input_img, outputs)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Creazione del modello U-Net\n",
    "unet = unet_model()\n",
    "unet.summary()\n",
    "\n",
    "unet.fit(\n",
    "    generator(train_dataset_batched, batch_size), \n",
    "    steps_per_epoch=20000 // batch_size,  # o len(train_dataset) // batch_size se è disponibile\n",
    "    epochs=10,\n",
    "    validation_data=generator(test_dataset_batched, batch_size),\n",
    "    validation_steps=10000 // batch_size  # o len(test_dataset) // batch_size se è disponibile)  # Adatta questi numeri in base alle tue esigenze\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante il progetto ho deciso di sperimentare anche l'uso di autoencoders. Purtroppo i risultati sono stati insoddisfacenti poichè l'mse risultava pari a circa 0.0035 e di conseguenza le immagini meno nitide. Ho anche provato ad aggiungere delle skip connections ma,anche se con risultati migliori, rimaneva comunque meno soddisfacente che con l'uso della U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queste sono invece le funzioni usate per calcolare l'mse e per stampare 3 immagini originali, mascherate e rigenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_scores = []\n",
    "\n",
    "for _ in range(10):  # Ripete il processo per 10 volte\n",
    "    mse_values = []\n",
    "    for i, (masked_imgs, original_imgs) in enumerate(test_generator):\n",
    "        if i >= 1250:  # 1250 batches of size 8 give 10000 images\n",
    "            break\n",
    "        reconstructed_imgs = unet.predict(masked_imgs)\n",
    "        mse = np.mean(np.power(original_imgs - reconstructed_imgs, 2))\n",
    "        mse_values.append(mse)\n",
    "\n",
    "    mse_scores.append(np.mean(mse_values))  # Media degli MSE per iterazione\n",
    "# Calcola il valore medio e la deviazione standard dell'MSE\n",
    "mean_mse = np.mean(mse_scores)\n",
    "std_mse = np.std(mse_scores)\n",
    "\n",
    "print(\"Mean MSE:\", mean_mse)\n",
    "print(\"Standard Deviation MSE:\", std_mse)\n",
    "\n",
    "masked_imgs, original_imgs = next(test_generator)\n",
    "regenerated_imgs = unet.predict(masked_imgs)\n",
    "\n",
    "# Numero di immagini da visualizzare\n",
    "num_imgs_to_show = 3\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "for i in range(num_imgs_to_show):\n",
    "    # Immagine originale\n",
    "    ax = plt.subplot(3, num_imgs_to_show, i + 1)\n",
    "    plt.imshow(original_imgs[i])\n",
    "    ax.set_title(\"Originale\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Immagine mascherata\n",
    "    ax = plt.subplot(3, num_imgs_to_show, num_imgs_to_show + i + 1)\n",
    "    plt.imshow(masked_imgs[i])\n",
    "    ax.set_title(\"Mascherata\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Immagine rigenerata\n",
    "    ax = plt.subplot(3, num_imgs_to_show, 2 * num_imgs_to_show + i + 1)\n",
    "    plt.imshow(regenerated_imgs[i])\n",
    "    ax.set_title(\"Rigenerata\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "<p>Model: \"model\"<p>\n",
    "__________________________________________________________________________________________________\n",
    " <p>Layer (type)                Output Shape                 Param #   Connected to<p>\n",
    "==================================================================================================</br>\n",
    " input_1 (InputLayer)        [(None, 64, 64, 3)]          0         []\n",
    "\n",
    " conv2d (Conv2D)             (None, 64, 64, 64)           1792      ['input_1[0][0]']\n",
    "\n",
    " conv2d_1 (Conv2D)           (None, 64, 64, 64)           36928     ['conv2d[0][0]']\n",
    "\n",
    " max_pooling2d (MaxPooling2  (None, 32, 32, 64)           0         ['conv2d_1[0][0]']\n",
    " D)\n",
    "\n",
    " conv2d_2 (Conv2D)           (None, 32, 32, 128)          73856     ['max_pooling2d[0][0]']\n",
    "\n",
    " conv2d_3 (Conv2D)           (None, 32, 32, 128)          147584    ['conv2d_2[0][0]']\n",
    "\n",
    " max_pooling2d_1 (MaxPoolin  (None, 16, 16, 128)          0         ['conv2d_3[0][0]']\n",
    " g2D)\n",
    "\n",
    " conv2d_4 (Conv2D)           (None, 16, 16, 256)          295168    ['max_pooling2d_1[0][0]']\n",
    "\n",
    " conv2d_5 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_4[0][0]']\n",
    "\n",
    " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 256)            0         ['conv2d_5[0][0]']\n",
    " g2D)\n",
    "\n",
    " conv2d_6 (Conv2D)           (None, 8, 8, 512)            1180160   ['max_pooling2d_2[0][0]']\n",
    "\n",
    " conv2d_7 (Conv2D)           (None, 8, 8, 512)            2359808   ['conv2d_6[0][0]']\n",
    "\n",
    " conv2d_transpose (Conv2DTr  (None, 16, 16, 256)          524544    ['conv2d_7[0][0]']\n",
    " anspose)\n",
    "\n",
    " concatenate (Concatenate)   (None, 16, 16, 512)          0         ['conv2d_transpose[0][0]',\n",
    "                                                                     'conv2d_5[0][0]']\n",
    "\n",
    " conv2d_8 (Conv2D)           (None, 16, 16, 256)          1179904   ['concatenate[0][0]']\n",
    "\n",
    " conv2d_9 (Conv2D)           (None, 16, 16, 256)          590080    ['conv2d_8[0][0]']\n",
    "\n",
    " conv2d_transpose_1 (Conv2D  (None, 32, 32, 128)          131200    ['conv2d_9[0][0]']\n",
    " Transpose)\n",
    "\n",
    " concatenate_1 (Concatenate  (None, 32, 32, 256)          0         ['conv2d_transpose_1[0][0]',\n",
    " )                                                                   'conv2d_3[0][0]']\n",
    "\n",
    " conv2d_10 (Conv2D)          (None, 32, 32, 128)          295040    ['concatenate_1[0][0]']\n",
    "\n",
    " conv2d_11 (Conv2D)          (None, 32, 32, 128)          147584    ['conv2d_10[0][0]']\n",
    "\n",
    " conv2d_transpose_2 (Conv2D  (None, 64, 64, 64)           32832     ['conv2d_11[0][0]']\n",
    " Transpose)\n",
    "\n",
    " concatenate_2 (Concatenate  (None, 64, 64, 128)          0         ['conv2d_transpose_2[0][0]',\n",
    " )                                                                   'conv2d_1[0][0]']\n",
    "\n",
    " conv2d_12 (Conv2D)          (None, 64, 64, 64)           73792     ['concatenate_2[0][0]']\n",
    "\n",
    " conv2d_13 (Conv2D)          (None, 64, 64, 64)           36928     ['conv2d_12[0][0]']\n",
    "\n",
    " conv2d_14 (Conv2D)          (None, 64, 64, 3)            195       ['conv2d_13[0][0]']\n",
    "\n",
    "==================================================================================================\n",
    "</br>Total params: 7697475 (29.36 MB)\n",
    "</br>Trainable params: 7697475 (29.36 MB)\n",
    "</br>Non-trainable params: 0 (0.00 Byte)\n",
    "__________________________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I risultati ottenuti dopo 10 epoche di training sono i seguenti</br>\n",
    "2500/2500 [==============================] - 1355s 541ms/step - loss: 0.0047 - val_loss: 0.0034</br>\n",
    "Epoch 2/10</br>\n",
    "2500/2500 [==============================] - 1444s 578ms/step - loss: 0.0034 - val_loss: 0.0033</br>\n",
    "Epoch 3/10</br>\n",
    "2500/2500 [==============================] - 1297s 519ms/step - loss: 0.0033 - val_loss: 0.0032</br>\n",
    "Epoch 4/10</br>\n",
    "2500/2500 [==============================] - 1278s 511ms/step - loss: 0.0032 - val_loss: 0.0031</br>\n",
    "Epoch 5/10</br>\n",
    "2500/2500 [==============================] - 1329s 531ms/step - loss: 0.0031 - val_loss: 0.0030</br>\n",
    "Epoch 6/10</br>\n",
    "2500/2500 [==============================] - 1384s 554ms/step - loss: 0.0030 - val_loss: 0.0033</br>\n",
    "Epoch 7/10</br>\n",
    "2500/2500 [==============================] - 1400s 560ms/step - loss: 0.0030 - val_loss: 0.0030</br>\n",
    "Epoch 8/10</br>\n",
    "2500/2500 [==============================] - 2502s 1s/step - loss: 0.0030 - val_loss: 0.0029</br>\n",
    "Epoch 9/10</br>\n",
    "2500/2500 [==============================] - 1424s 570ms/step - loss: 0.0029 - val_loss: 0.0029</br>\n",
    "Epoch 10/10</br>\n",
    "2500/2500 [==============================] - 1355s 542ms/step - loss: 0.0029 - val_loss: 0.0028</br></br>\n",
    "Mean MSE: 0.0025848561667753647</br>\n",
    "Standard Deviation MSE: 1.360791075543637e-05\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
